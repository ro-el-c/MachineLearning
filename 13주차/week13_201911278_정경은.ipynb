{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4+eZTUfZ5NBZHY7dQGoMa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuoTddzssEdh","executionInfo":{"status":"ok","timestamp":1669799841435,"user_tz":-540,"elapsed":5237,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}},"outputId":"59b3fe20-efa9-40f2-ddb8-32e3905de413"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"]},{"cell_type":"code","source":["from torch.utils.data import (DataLoader, TensorDataset)\n","from torch import nn\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","import os\n","\n","class TransformerChat(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","\n","        self.vocab_size = config[\"vocab_size\"]\n","        self.embedding_size = config['embedding_size']\n","        self.num_heads = config['num_heads']\n","        self.num_encoder_layers = config['num_encoder_layers']\n","        self.num_decoder_layers = config['num_decoder_layers']\n","        self.max_length = config['max_length']\n","        self.hidden_size = config['hidden_size']\n","        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_size)\n","        self.transformer = nn.Transformer(d_model=self.embedding_size, nhead=self.num_heads, num_encoder_layers=self.num_encoder_layers,\n","                                          num_decoder_layers=self.num_decoder_layers, dim_feedforward=self.hidden_size)\n","        self.mask = self.transformer.generate_square_subsequent_mask(self.max_length).cuda()\n","        self.projection_layer = nn.Linear(self.embedding_size, self.vocab_size)\n","\n","    def forward(self, enc_inputs, dec_inputs):\n","        enc_input_features = self.embeddings(enc_inputs).transpose(0, 1)\n","        dec_input_features = self.embeddings(dec_inputs).transpose(0, 1)\n","        dec_output_features = self.transformer(src=enc_input_features, tgt=dec_input_features, src_mask = self.mask, tgt_mask = self.mask)\n","        hypothesis = self.projection_layer(dec_output_features)\n","\n","        return hypothesis"],"metadata":{"id":"XAUDSLXqtAey","executionInfo":{"status":"ok","timestamp":1669799841435,"user_tz":-540,"elapsed":9,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["def load_vocab(file_dir):\n","\n","    with open(file_dir,'r',encoding='utf8') as vocab_file:\n","        char2idx = {}\n","        idx2char = {}\n","        index = 0\n","        for char in vocab_file:\n","            char = char.strip()\n","            char2idx[char] = index\n","            idx2char[index] = char\n","            index+=1\n","\n","    return char2idx, idx2char\n","\n","def convert_data2feature(config, input_sequence, char2idx, decoder_input=False):\n","    input_features = np.zeros(config[\"max_length\"], dtype=np.int)\n","\n","    if decoder_input:\n","        input_sequence = \" \".join([\"<S>\"] + input_sequence.split()[:-1])\n","\n","    for idx,token in enumerate(input_sequence.split()):\n","        if token in char2idx.keys():\n","            input_features[idx] = char2idx[token]\n","        else:\n","            input_features[idx] = char2idx['<UNK>']\n","\n","    return input_features\n","\n","def load_dataset(config):\n","    char2idx, idx2char = load_vocab(config['vocab_file'])\n","\n","    file_dir = config['train_file']\n","    data_file = open(file_dir,'r',encoding='utf8').readlines()\n","    \n","    enc_inputs, dec_inputs, dec_outputs = [], [], []\n","\n","    for line in tqdm(data_file):\n","\n","        line = line.strip().split('\\t')\n","\n","        input_sequence = line[0]\n","        output_sequence = line[1]\n","\n","        enc_inputs.append(convert_data2feature(config, input_sequence, char2idx))\n","        dec_inputs.append(convert_data2feature(config, output_sequence, char2idx, True))\n","        dec_outputs.append(convert_data2feature(config, output_sequence, char2idx))\n","\n","    enc_inputs = torch.tensor(enc_inputs, dtype=torch.long)\n","    dec_inputs = torch.tensor(dec_inputs, dtype=torch.long)\n","    dec_outputs = torch.tensor(dec_outputs, dtype=torch.long)\n","\n","    return enc_inputs, dec_inputs, dec_outputs, char2idx, idx2char"],"metadata":{"id":"xNxae52FtR4N","executionInfo":{"status":"ok","timestamp":1669799841436,"user_tz":-540,"elapsed":8,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","def do_test(config, model, word2idx, idx2word, input_sequence=\"오늘 약속있으세요?\"):\n","    model.eval()\n","    input_sequence = \" \".join([e if e != \" \" else \"<SP>\" for e in input_sequence])\n","    enc_inputs = torch.tensor([convert_data2feature(config, input_sequence, word2idx)], dtype=torch.long).cuda()\n","    dec_inputs = torch.tensor([convert_data2feature(config, \"\", word2idx, True)], dtype=torch.long).cuda()\n","    response = ''\n","\n","    for decoding_step in range(config['max_length']-1):\n","        dec_outputs = model(enc_inputs, dec_inputs)[decoding_step, 0, :]\n","        dec_output_idx = np.argmax(tensor2list(dec_outputs))\n","        dec_inputs[0][decoding_step+1] = dec_output_idx\n","        if idx2word[dec_output_idx] == \"</S>\":\n","            break\n","        response += idx2word[dec_output_idx]\n","    \n","    print(response.replace(\"<SP>\", \" \"))\n","\n","def test(config):\n","    word2idx, idx2word = load_vocab(config['vocab_file'])\n","    model = TransformerChat(config).cuda()\n","    model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"trained_model_name\"])))\n","\n","    while(True):\n","        input_sequence = input(\"문장을 입력하세요. (종료는 exit을 입력하세요.) : \")\n","        if input_sequence == 'exit':\n","            break\n","        do_test(config, model, word2idx, idx2word, input_sequence)"],"metadata":{"id":"R5Aj_fsHtb1b","executionInfo":{"status":"ok","timestamp":1669799841436,"user_tz":-540,"elapsed":7,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["def train(config):\n","    model = TransformerChat(config).cuda()\n","    enc_inputs, dec_inputs, dec_outputs, word2idx, idx2word = load_dataset(config)\n","    train_features = TensorDataset(enc_inputs, dec_inputs, dec_outputs)\n","    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learn_rate\"])\n","    for epoch in range(config[\"epoch\"] + 1):\n","        for (step, batch) in enumerate(train_dataloader):\n","            model.train()\n","            batch = tuple(t.cuda() for t in batch)\n","            optimizer.zero_grad()\n","            enc_inputs, dec_inputs, dec_outputs = batch\n","            hypothesis = model(enc_inputs, dec_inputs).view(-1, config['vocab_size'])\n","            labels = dec_outputs.transpose(0, 1)\n","            labels = labels.reshape(config[\"max_length\"]*dec_inputs.size(0))\n","            loss = loss_func(hypothesis, labels)\n","            loss.backward()\n","            optimizer.step()\n","            if (step+1)% 200 == 0:\n","                print(\"Current Step : {0:d} / {1:d}\\tCurrent Loss : {2:f}\".format(step+1, int(len(enc_inputs) / config['batch_size']), loss.item()))\n","        torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))"],"metadata":{"id":"rHOexbSUtoom","executionInfo":{"status":"ok","timestamp":1669799841436,"user_tz":-540,"elapsed":6,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["if(__name__==\"__main__\"):\n","\n","    root_dir = \"/gdrive/My Drive/ml_colab/week13/\"\n","    output_dir = os.path.join(root_dir, \"chatbot\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","    config = {\"mode\": \"test\",\n","              \"vocab_file\": os.path.join(root_dir, \"vocab.txt\"),\n","              \"train_file\": os.path.join(root_dir, \"train.txt\"),\n","              \"trained_model_name\":\"epoch_{}.pt\".format(5),\n","              \"output_dir\":output_dir,\n","              \"epoch\": 5,\n","              \"learn_rate\":0.00005,\n","              \"num_encoder_layers\": 6,\n","              \"num_decoder_layers\": 6,\n","              \"num_heads\": 4,\n","              \"max_length\": 20,\n","              \"batch_size\": 128,\n","              \"embedding_size\": 256,\n","              \"hidden_size\": 512,\n","              \"vocab_size\": 4427\n","            }\n","\n","\n","    if(config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0h3vuSQ9ty9U","executionInfo":{"status":"ok","timestamp":1669800966225,"user_tz":-540,"elapsed":60777,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}},"outputId":"9a288fae-57ca-4a0f-8884-389a757db22e"},"execution_count":67,"outputs":[{"name":"stdout","output_type":"stream","text":["문장을 입력하세요. (종료는 exit을 입력하세요.) : 유머\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  app.launch_new_instance()\n"]},{"name":"stdout","output_type":"stream","text":["(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 나한테 욕하는 거야..?\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 너 진짜 못됐다!!\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 속상해\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 나한테 왜 그래ㅜ\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 나쁘다\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : ㅜㅜㅜ\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 유머라며!!!\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 됐어\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 안해\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : 흥\n","(이름) (비속어) (비속어)\n","문장을 입력하세요. (종료는 exit을 입력하세요.) : exit\n"]}]}]}