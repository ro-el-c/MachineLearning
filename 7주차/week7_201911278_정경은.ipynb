{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMZaUgUEA+mkV5QVfi+1S5P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Week 7 - ANN\n","\n"],"metadata":{"id":"MFEUlnfRpKYC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"metadata":{"id":"gWCQCpybpumR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665621940393,"user_tz":-540,"elapsed":10491,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}},"outputId":"06fd5ec6-350f-4532-de31-11ba2407d206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score\n","\n","# 데이터 읽기 함수\n","def load_dataset(file):\n","  data = np.loadtxt(file)\n","  print(\"DATA=\",data)\n","  \n","  input_features = data[:,0:-1] # 모든 행에 대하여, 맨 처음부터 뒤에서 두 번째까지 모두 가져와라 // 맨 마지막 열 빼고 입력값이기 때문\n","  print(\"X=\",input_features)\n","  \n","  labels = np.reshape(data[:,-1],(4,1)) # 모든 행에 대하여 마지막 열을 (4행, 1열)로 바꾸어 가져옴 // 2차원으로 바꾸고 벡터화.\n","  print(\"Y=\",labels)\n"," \n","  input_features = torch.tensor(input_features, dtype=torch.float)\n","  labels = torch.tensor(labels, dtype=torch.float)\n","\n","  return (input_features, labels)\n","\n","# 모델 평가 결과 계산을 위해 텐서를 리스트로 변환하는 함수\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","x, y = load_dataset(\"/gdrive/My Drive/ml_colab/week7/train.txt\")\n","# 본 강의에서는 항상 load_dataset으로 할 것\n","\n","# 2 by 2 matrix -> 정규 분포\n","\n","\n","\n","# layer 1 가중치 초기화\n","w1 = torch.randn(2, 2, requires_grad=True) # requires_grad: gradient 전파 -> 이 값으로 인해 바뀌도록 (?)\n","b1 = torch.randn(2, requires_grad=True)\n","\n","print(\"\\n[Init]\\nw1 = {0}\".format(tensor2list(w1)))\n","print(\"b1 = {0}\".format(tensor2list(b1)))\n","\n","\n","# layer 2 가중치 초기화\n","w2 = torch.randn(2, 1, requires_grad=True)\n","b2 = torch.randn(1, requires_grad=True)\n","\n","print(\"w2 = {0}\".format(tensor2list(w2)))\n","print(\"b2 = {0}\\n\".format(tensor2list(b2)))\n","\n","\n","\n","### 참고 - NA == 계산할 수 없음. (underflow 등의 이유)\n","\n","\n","# Activation 함수 설정\n","sigmoid = nn.Sigmoid()\n","\n","# Cost 함수 - 이진분류 크로스엔트로피 비용 함수 설정 \n","loss_func = torch.nn.BCELoss()\n","\n","# 옵티마이저 함수 (역전파 알고리즘을 수행할 함수)\n","optimizer = torch.optim.SGD([w1, b1, w2, b2], lr=0.05) # SGD - Stochastic Gradient Descent\n","\n","\n","\n","\"\"\" 모델 학습 \"\"\"\n","for epoch in range(1001):\n","\n","    # H(X) 계산: forward 연산\n","    L2 = sigmoid(torch.add(torch.matmul(x, w1), b1)) # 1층\n","    hx = sigmoid(torch.add(torch.matmul(L2, w2), b2)) # 2층\n","\n","\n","    \"\"\" w, b 값 update 시작 \"\"\"\n","    # 비용 계산\n","    cost = loss_func(hx, y)\n","\n","    # 역전파 수행\n","    cost.backward()\n","    optimizer.step() # optimizer 실행\n","    \"\"\" w, b 값 update 끝 \"\"\"\n","    # if cost 가 굉장히 작아져 0이랑 가가워지면 break\n","\n","\n","    # 100 에폭마다 비용 출력\n","    if epoch % 100 == 0:\n","        print(epoch, cost.item())\n","\n","print(\"\\n[Learned]\\nw1 = {0}\".format(tensor2list(w1)))\n","print(\"b1 = {0}\".format(tensor2list(b1)))\n","print(\"w2 = {0}\".format(tensor2list(w2)))\n","print(\"b2 = {0}\\n\".format(tensor2list(b2)))\n","\n","\n","\"\"\" 모델 평가 \"\"\"\n","# H(X) 계산: forward 연산\n","L2 = sigmoid(torch.add(torch.matmul(x, w1), b1))\n","hx = sigmoid(torch.add(torch.matmul(L2, w2), b2))\n","\n","\n","# hx는 1이 안 나옴. sigmoid 함수 결과 값이기 때문\n","logits = (hx > 0.5).float()\n","predicts = tensor2list(logits)\n","golds = tensor2list(y)\n","\n","\n","print(\"\\nPRED=\",predicts)\n","print(\"GOLD=\",golds)\n","print(\"Accuracy : {0:f}\".format(accuracy_score(golds, predicts)))"],"metadata":{"id":"Ym8fNnoUpvbn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665622248583,"user_tz":-540,"elapsed":429,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}},"outputId":"7f8d500a-a8fb-4a12-ef66-c6c567317523"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["DATA= [[0. 0. 0.]\n"," [0. 1. 1.]\n"," [1. 0. 1.]\n"," [1. 1. 0.]]\n","X= [[0. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 1.]]\n","Y= [[0.]\n"," [1.]\n"," [1.]\n"," [0.]]\n","\n","[Init]\n","w1 = [[-1.6039015054702759, 0.9669446349143982], [1.6664398908615112, -0.37710168957710266]]\n","b1 = [-0.9097310900688171, 0.5180159211158752]\n","w2 = [[0.09386227279901505], [1.209526777267456]]\n","b2 = [-0.530109167098999]\n","\n","0 0.7102298736572266\n","100 0.5373131036758423\n","200 0.09103536605834961\n","300 4.188831735518761e-05\n","400 5.066399353381712e-07\n","500 8.940698137394065e-08\n","600 2.9802322387695312e-08\n","700 0.0\n","800 0.0\n","900 0.0\n","1000 0.0\n","\n","[Learned]\n","w1 = [[-69.9582748413086, 60.21929931640625], [67.64826965332031, -96.91239166259766]]\n","b1 = [-58.37643814086914, -40.59731674194336]\n","w2 = [[83.81919860839844], [125.75112915039062]]\n","b2 = [-62.66192626953125]\n","\n","\n","PRED= [[0.0], [1.0], [1.0], [0.0]]\n","GOLD= [[0.0], [1.0], [1.0], [0.0]]\n","Accuracy : 1.000000\n"]}]}]}