{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Week 7 실습\n","\n","\n","Activation 함수: Sigmoid<br>\n","Cost 함수: Binary Cross Entrophy (BCE) / 이진 분류\n","\n","<br>\n","<br>\n","\n","H(X) = 1/(1+e^(-W^T*X))<br>\n","Cost(w) = -1/m * sigma{ylog(H(X))+(1-y)log(1-H(X))}\n","\n","<br>\n","<br>\n","\n","pytorch - 페이스북에서 만든 NN 라이브러리<br>\n","tensorflow - 구글"],"metadata":{"id":"czzkb5odsHir"}},{"cell_type":"code","metadata":{"id":"FdZnDI8azinw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665621909248,"user_tz":-540,"elapsed":4529,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}},"outputId":"a9d43115-beea-4a07-e169-b15415f612f2"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"JBGiT1Qw_Qzo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665621913564,"user_tz":-540,"elapsed":924,"user":{"displayName":"alcxzp","userId":"00037678357315986784"}},"outputId":"acbb6939-ef87-478d-9b78-5541872e764e"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score\n","\n","# 데이터 읽기 함수\n","def load_dataset(file):\n","  data = np.loadtxt(file)\n","  print(\"DATA=\",data)\n","  \n","  input_features = data[:,0:-1] # 모든 행에 대하여, 맨 처음부터 뒤에서 두 번째까지 모두 가져와라 // 맨 마지막 열 빼고 입력값이기 때문\n","  print(\"X=\",input_features)\n","  \n","  labels = np.reshape(data[:,-1],(4,1)) # 모든 행에 대하여 마지막 열을 (4행, 1열)로 바꾸어 가져옴 // 2차원으로 바꾸고 벡터화.\n","  print(\"Y=\",labels)\n"," \n","  input_features = torch.tensor(input_features, dtype=torch.float)\n","  labels = torch.tensor(labels, dtype=torch.float)\n","\n","  return (input_features, labels)\n","\n","# 모델 평가 결과 계산을 위해 텐서를 리스트로 변환하는 함수\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","x, y = load_dataset(\"/gdrive/My Drive/ml_colab/week7/train.txt\")\n","# 본 강의에서는 항상 load_dataset으로 할 것\n","\n","# 2 by 2 matrix -> 정규 분포\n","\n","\n","\n","# layer 1 가중치 초기화\n","w1 = torch.randn(2, 2, requires_grad=True) # requires_grad: gradient 전파 -> 이 값으로 인해 바뀌도록 (?)\n","b1 = torch.randn(2, requires_grad=True)\n","\n","print(\"\\n[Init]\\nw1 = {0}\".format(tensor2list(w1)))\n","print(\"b1 = {0}\".format(tensor2list(b1)))\n","\n","\n","# layer 2 가중치 초기화\n","w2 = torch.randn(2, 1, requires_grad=True)\n","b2 = torch.randn(1, requires_grad=True)\n","\n","print(\"w2 = {0}\".format(tensor2list(w2)))\n","print(\"b2 = {0}\\n\".format(tensor2list(b2)))\n","\n","\n","\n","### 참고 - NA == 계산할 수 없음. (underflow 등의 이유)\n","\n","\n","# Activation 함수 설정\n","sigmoid = nn.Sigmoid()\n","\n","# Cost 함수 - 이진분류 크로스엔트로피 비용 함수 설정 \n","loss_func = torch.nn.BCELoss()\n","\n","# 옵티마이저 함수 (역전파 알고리즘을 수행할 함수)\n","optimizer = torch.optim.SGD([w1, b1, w2, b2], lr=0.2) # SGD - Stochastic Gradient Descent\n","\n","\n","\n","\"\"\" 모델 학습 \"\"\"\n","for epoch in range(1001):\n","\n","    # H(X) 계산: forward 연산\n","    L2 = sigmoid(torch.add(torch.matmul(x, w1), b1)) # 1층\n","    hx = sigmoid(torch.add(torch.matmul(L2, w2), b2)) # 2층\n","\n","\n","    \"\"\" w, b 값 update 시작 \"\"\"\n","    # 비용 계산\n","    cost = loss_func(hx, y)\n","\n","    # 역전파 수행\n","    cost.backward()\n","    optimizer.step() # optimizer 실행\n","    \"\"\" w, b 값 update 끝 \"\"\"\n","    # if cost 가 굉장히 작아져 0이랑 가가워지면 break\n","\n","\n","    # 100 에폭마다 비용 출력\n","    if epoch % 100 == 0:\n","        print(epoch, cost.item())\n","\n","print(\"\\n[Learned]\\nw1 = {0}\".format(tensor2list(w1)))\n","print(\"b1 = {0}\".format(tensor2list(b1)))\n","print(\"w2 = {0}\".format(tensor2list(w2)))\n","print(\"b2 = {0}\\n\".format(tensor2list(b2)))\n","\n","\n","\"\"\" 모델 평가 \"\"\"\n","# H(X) 계산: forward 연산\n","L2 = sigmoid(torch.add(torch.matmul(x, w1), b1))\n","hx = sigmoid(torch.add(torch.matmul(L2, w2), b2))\n","\n","\n","# hx는 1이 안 나옴. sigmoid 함수 결과 값이기 때문\n","logits = (hx > 0.5).float()\n","predicts = tensor2list(logits)\n","golds = tensor2list(y)\n","\n","\n","print(\"\\nPRED=\",predicts)\n","print(\"GOLD=\",golds)\n","print(\"Accuracy : {0:f}\".format(accuracy_score(golds, predicts)))\n","\n","# 실행할 때마다 정확도 다름\n","# learning rate에 따라 정확도 달라짐"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["DATA= [[0. 0. 0.]\n"," [0. 1. 1.]\n"," [1. 0. 1.]\n"," [1. 1. 0.]]\n","X= [[0. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 1.]]\n","Y= [[0.]\n"," [1.]\n"," [1.]\n"," [0.]]\n","\n","[Init]\n","w1 = [[0.0356321707367897, 0.4883567988872528], [1.2429121732711792, 0.30365464091300964]]\n","b1 = [-0.6879940629005432, 0.6543421149253845]\n","w2 = [[-0.21267671883106232], [-3.268977403640747]]\n","b2 = [1.6433985233306885]\n","\n","0 0.7945843935012817\n","100 0.6995856165885925\n","200 0.48612305521965027\n","300 0.4998161196708679\n","400 0.5338734984397888\n","500 0.5009685754776001\n","600 0.4810628294944763\n","700 0.5293934941291809\n","800 0.507781982421875\n","900 0.47923383116722107\n","1000 0.5223032832145691\n","\n","[Learned]\n","w1 = [[-8.16952133178711, 164.4059600830078], [-27.802165985107422, -78.1342544555664]]\n","b1 = [-36.44888687133789, -164.80804443359375]\n","w2 = [[-4.96284294128418], [114.92253112792969]]\n","b2 = [-1.3874603509902954]\n","\n","\n","PRED= [[0.0], [0.0], [1.0], [0.0]]\n","GOLD= [[0.0], [1.0], [1.0], [0.0]]\n","Accuracy : 0.750000\n"]}]}]}