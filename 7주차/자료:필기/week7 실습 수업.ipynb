{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPBD+F3Ean5zuSl7LpWLBpx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Week 7 - ANN\n","<br>\n","\n","Multi-layer Perceptron 이 하는 역할\n","\n","**한 층 거치며 다른 좌표로 -> linear 문제로** ; 커널 트릭이 하는 일\n","\n","<br>\n","softmax에서 exponential을 붙이는 이유?<br>\n",": log 안에 출력값. 그 출력값을 확률값으로 가정.<br>\n","log를 벗기고 싶으면 exponential을 붙여줘야 함\n","<br>-> ex. log 의 p 값 -> p 값 얻으려면 log의 역함수 == exponential\n","\n","<br>\n","<br>\n","trainig - argmax X<br>\n","predict - argmax O"],"metadata":{"id":"MFEUlnfRpKYC"}}]}